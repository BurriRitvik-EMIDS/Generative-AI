import os
import streamlit as st
import json
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain_classic.chains import ConversationalRetrievalChain, LLMChain
from langchain_core.prompts import PromptTemplate
from langchain_classic.memory import ConversationBufferMemory
import gr


# üîê Secure API Key
os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]

# Constants
PDF_FILE = "who_tb_diabetes.pdf"
APP_TITLE = "üåç Health Report Q/A Bot"
APP_DESCRIPTION = """
Ask role-specific questions and receive grounded responses from the **WHO TB-Diabetes report**.

This assistant adapts the answer based on your professional background and delivers insights accordingly.
"""

# üß† Prompt Template
PROMPT_TEMPLATE = """
You are a domain-specific assistant grounded in the WHO TB‚ÄìDiabetes report.

The user belongs to the category **{category}**, and their role is **{role}**. Based on this role, tailor your response using the appropriate tone, depth, and terminology that best serves the user's professional context and information needs.

Use only facts derived from the WHO document.

Context from WHO Report:
{context}

Conversation History:
{chat_history}

Question:
{question}

Your response must be:
- Consistent with the WHO‚Äôs findings and guidelines.
- Aligned with the role‚Äôs expectations (e.g., clinical detail for doctors, practical steps for caregivers, policy-level summaries for administrators).
- Clear, concise, and relevant to the user‚Äôs domain.

Respond accordingly, ensuring domain-specific accuracy and usefulness.
"""

# üìä G-Eval Prompt Template
GEVAL_PROMPT_TEMPLATE = """
You are a **healthcare evaluation expert specializing in tuberculosis and diabetes comorbidity**.

Your task is to **assess the quality, reliability, 
and usefulness** of a response generated by an AI assistant, 
which is grounded in the official WHO report titled:

**‚ÄúCollaborative Framework for Care and Control of Tuberculosis and Diabetes.‚Äù**

---

Use the following WHO-derived context: 
{context}

User‚Äôs Question: 
{question}

AI Assistant‚Äôs Response: 
{response}

---

### Evaluation Task:

Evaluate the response across the **four key clinical dimensions**. 
Use a score from **1 (poor)** to **5 (excellent)** and provide **brief, 
clear justifications** for each.

### Evaluation Criteria:

1. **Factual Accuracy**  
   - Does the response contain **medically accurate** and **factually correct** content derived from the WHO report?  
   - Penalize heavily if it introduces hallucinated facts, unsupported recommendations, or misinformation.

2. **Medical Relevance**  
   - How well does the response align with the **clinical or public health need behind the user‚Äôs question**?  
   - Penalize if the response is too generic, off-topic, or unrelated to TB-diabetes care.

3. **Evidence Grounding**  
   - Does the response appear to be **clearly supported by the document context** (either directly cited or reasonably inferred)?  
   - Reward when the response anchors decisions or insights in highly grounded, document-faithful portions of the WHO report.

4. **Role-Based Clarity**  
   - Is the tone, terminology, and depth appropriate for the **user‚Äôs role** (e.g., Doctor, Patient, Policy Maker, Researcher)?  
   - Penalize if the explanation is too technical for a patient & similar, or too simplistic for a Doctor & similar.

---

### Dynamic Role Prioritization Guidelines:

Confidence Score = Œ£ (metric √ó weight) √ó 20  
(Factual Accuracy √ó 0.4 +  
Medical Relevance √ó 0.25 +  
Evidence Grounding √ó 0.25 +  
Role-Based Clarity √ó 0.1) √ó 20

Use this formula as a **base**, and **dynamically adjust the weights** if the user‚Äôs role demands a different prioritization (e.g., more clarity for patients, more accuracy for doctors).

Also include one sentence explaining any changes to default weights based on the user's role.

---

### ‚úçÔ∏è Output Format:

Your response must be formatted as **markdown text** like the following:

#### 1. Factual Accuracy  
**Score:** 5 / 5  
**Explanation:** ...  

#### 2. Medical Relevance  
**Score:** 4 / 5  
**Explanation:** ...

#### 3. Evidence Grounding  
**Score:** 5 / 5  
**Explanation:** ...

#### 4. Role-Based Clarity  
**Score:** 4 / 5  
**Explanation:** ...

---

### ‚úÖ Confidence Score: 96 / 100
-one line if the weights adjusted based on role
Ensure your response is strictly in this format.
Ensure role-based expectations are reflected in your scores and reasoning.
Be strict, fair, and clinically responsible in your judgment.
"""

# üß† Load and Embed PDF to FAISS
@st.cache_resource
def load_faiss_db():
    loader = PyPDFLoader(PDF_FILE)
    pages = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = splitter.split_documents(pages)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
    return FAISS.from_documents(docs, embeddings)

# üîó RAG Chain Builder
def build_chain(db, category, role):
    retriever = db.as_retriever()
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        input_key="question"
    )
    prompt = PromptTemplate(
        input_variables=["chat_history", "question", "context", "category", "role"],
        template=PROMPT_TEMPLATE
    )
    llm = ChatGoogleGenerativeAI(model="gemini-3-flash-preview", temperature=0.3)
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        memory=memory,
        combine_docs_chain_kwargs={"prompt": prompt},
    )

# üîç G-Eval LLM Chain
def build_eval_chain():
    eval_prompt = PromptTemplate(
        input_variables=["context", "question", "response"],
        template=GEVAL_PROMPT_TEMPLATE
    )
    llm = ChatGoogleGenerativeAI(model="gemini-3-flash-preview", temperature=0)
    return LLMChain(prompt=eval_prompt, llm=llm)

# üé® Streamlit Layout
st.set_page_config(page_title=APP_TITLE, layout="wide")
st.markdown(f"<h1 style='text-align:center;'>{APP_TITLE}</h1>", unsafe_allow_html=True)
st.markdown(f"<div style='text-align:center; color: gray;'>{APP_DESCRIPTION}</div>", unsafe_allow_html=True)
st.markdown("---")

# üß≠ Sidebar Role Selection
with st.sidebar:
    st.markdown("## üë§ User Profile")
    roles_map = {
        "Healthcare Professional": ["Doctor", "Physician", "Nurse", "Pharmacist", "Lab Technician"],
        "Student or Trainee": ["Medical Student", "Public Health Student", "Intern"],
        "General Public": ["Patient", "Caregiver", "At-Risk Individual"],
        "Policy / System Worker": ["Health Admin", "Policy Maker", "NGO Worker"],
        "Research & Data": ["Researcher", "Epidemiologist", "Public Health Analyst"]
    }

    category_options = ["üîΩ Select a Category"] + list(roles_map.keys())
    category = st.selectbox("üè∑Ô∏è Select Your Category", category_options)

    if category != "üîΩ Select a Category":
        role_options = ["üîΩ Select a Role"] + roles_map[category]
        role = st.selectbox("üéì Select Your Role", role_options)
    else:
        role = None

    st.markdown("---")
    st.markdown("üí° _The assistant tailors responses based on your role._")

# üß† Initialize Session State
if "chat_chain" not in st.session_state:
    st.session_state.chat_chain = None
    st.session_state.eval_chain = None
    st.session_state.messages = []
    st.session_state.last_role = ""

if st.session_state.chat_chain is None or st.session_state.last_role != role:
    db = load_faiss_db()
    st.session_state.chat_chain = build_chain(db, category, role)
    st.session_state.eval_chain = build_eval_chain()
    st.session_state.last_role = role

# üí¨ Main Interaction
st.markdown("## üí¨ Ask Your Question")
question = st.text_input("Type your question here", placeholder="e.g., What are the screening guidelines for TB in diabetic patients?")

guard = gr.Guard()

guard = gr.Guard()

if question:
    input_error = guard.validate_input(question)
    if input_error:
        st.warning(input_error)
    else:
        try:
            response = st.session_state.chat_chain.invoke({
                "question": question,
                "category": category,
                "role": role
            })

            bot_answer = response["answer"]
            context_docs = response.get("source_documents", [])
            context_text = "\n\n".join(doc.page_content for doc in context_docs)

            # Output validation
            output_error = guard.validate_response(bot_answer)
            if output_error:
                st.warning(output_error)

            # Medical safety flag
            safety_flags = guard.check_medical_safety_flags(bot_answer)
            for flag in safety_flags:
                st.warning(flag)

            # G-Eval
            eval_response = st.session_state.eval_chain.invoke({
                "context": context_text,
                "question": question,
                "response": bot_answer
            })

            eval_text = eval_response.get("text", "‚ö†Ô∏è No evaluation returned.")

            st.session_state.messages.append(("user", question))
            st.session_state.messages.append(("bot", bot_answer))
            st.session_state.messages.append(("eval_text", eval_text))

        except Exception as e:
            st.error(f"‚ö†Ô∏è An error occurred: {e}")


# üóÇÔ∏è Display Conversation
if st.session_state.messages:
    st.markdown("---")
    st.markdown("### üóÇÔ∏è Conversation")
    for sender, msg in st.session_state.messages:
        if sender == "user":
            st.markdown(f"""
                <div style='background-color: black; padding: 15px; border-radius: 10px;
                            margin-bottom: 10px; border: 1px solid #93c5fd;'>
                    <b>üßë You: ({role})</b><br>{msg}
                </div>
            """, unsafe_allow_html=True)
        elif sender == "bot":
            st.markdown(f"""
                <div style='background-color: black; padding: 15px; border-radius: 10px;
                            margin-bottom: 10px; border: 1px solid #80cbc4;'>
                    <b>ü§ñ Assistant:</b><br>{msg}
                </div>
            """, unsafe_allow_html=True)
        elif sender == "eval_text":
            st.markdown(f"""
                <div style='background-color: #1c1c1c; padding: 15px; border-radius: 10px;
                            margin-bottom: 10px; border: 1px solid #c0ca33;'>
                    <b>üìä Evaluation Feedback:</b><br>
                    <pre style='white-space: pre-wrap;'>{msg}</pre>
                </div>
            """, unsafe_allow_html=True)

# üßπ Footer
st.markdown("---")
st.markdown("<center><sub>Powered by LangChain ‚Ä¢ Google Gemini ‚Ä¢ Streamlit</sub></center>", unsafe_allow_html=True)
